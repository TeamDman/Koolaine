{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet fastapi uvicorn nest-asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> why is nest_asyncio required?\n",
    "\n",
    "#### ChatGPT\n",
    "\n",
    "The `nest_asyncio` library is used to \"patch\" Python's standard library asyncio event loop to allow nested use of `asyncio.run` and event loops. This is particularly useful in environments like Jupyter Notebook where the event loop is already running in the background to handle things like cell execution and various I/O operations.\n",
    "\n",
    "In a standard Python script, you generally control the event loop yourself. When you execute an ASGI app using Uvicorn or any other ASGI server, the server takes control of the event loop to handle HTTP requests asynchronously.\n",
    "\n",
    "In contrast, Jupyter Notebook already has an event loop running to manage its interactive environment. This can lead to issues when you try to run another event loop for your FastAPI application on top of it. By using `nest_asyncio`, you patch the existing event loop to support nesting, effectively allowing the FastAPI event loop to run inside the Jupyter event loop without conflicts.\n",
    "\n",
    "Without `nest_asyncio`, you'd likely run into an error like:\n",
    "\n",
    "```\n",
    "RuntimeError: This event loop is already running\n",
    "```\n",
    "\n",
    "This library resolves that issue, enabling you to run asynchronous code like FastAPI apps directly within Jupyter cells. Given your technical background, you can think of `nest_asyncio` as a workaround to make two event-driven systems coexist peacefully within the same Python process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\ml\\glados-tts-upstream\n"
     ]
    }
   ],
   "source": [
    "%cd G:\\ml\\glados-tts-upstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.14.1 requires torch==1.13.1, but you have torch 2.0.1 which is incompatible.\n",
      "torchaudio 0.13.1 requires torch==1.13.1, but you have torch 2.0.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing TTS Engine...\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/R2D2FISH/glados-tts\n",
    "from glados import tts_runner\n",
    "glados = tts_runner(False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Tacotron took 75.19173622131348ms\n",
      "HiFiGAN took 540.1718616485596ms\n"
     ]
    }
   ],
   "source": [
    "glados.speak(\"Hello, world!\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, Request\n",
    "app = FastAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.get(\"/\")\n",
    "def read_root():\n",
    "    return {\"message\": \"Hello, World!\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.post(\"/say\")\n",
    "async def echo(request: Request):\n",
    "    body = await request.body()\n",
    "    text = body.decode(\"utf-8\")\n",
    "    glados.speak(text, True)\n",
    "    return {\"echo\": text}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_glados_server():\n",
    "    import uvicorn\n",
    "    # The host and port parameters are optional\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
    "    # this gets weird because the output gets dumped in future cells, whatever\n",
    "\n",
    "import threading\n",
    "glados_thread = threading.Thread(target=run_glados_server)\n",
    "glados_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [26644]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Tacotron took 73.23813438415527ms\n",
      "HiFiGAN took 539.7112369537354ms\n",
      "INFO:     127.0.0.1:54105 - \"POST /say HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "requests.post(\"http://localhost:8000/say\", data=\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet SpeechRecognition openai-whisper loguru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\teamd\\.conda\\envs\\torch\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\teamd\\.conda\\envs\\torch\\lib\\site-packages (0.14.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\teamd\\.conda\\envs\\torch\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\teamd\\.conda\\envs\\torch\\lib\\site-packages (from torch) (3.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\teamd\\.conda\\envs\\torch\\lib\\site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\teamd\\.conda\\envs\\torch\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\teamd\\.conda\\envs\\torch\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: filelock in c:\\users\\teamd\\.conda\\envs\\torch\\lib\\site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\teamd\\.conda\\envs\\torch\\lib\\site-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: requests in c:\\users\\teamd\\.conda\\envs\\torch\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torchvision-0.16.0%2Bcu118-cp310-cp310-win_amd64.whl (5.0 MB)\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torch-2.1.0%2Bcu118-cp310-cp310-win_amd64.whl (2722.7 MB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\teamd\\.conda\\envs\\torch\\lib\\site-packages (from torchvision) (9.3.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\teamd\\.conda\\envs\\torch\\lib\\site-packages (from torch) (2023.4.0)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torchaudio-2.1.0%2Bcu118-cp310-cp310-win_amd64.whl (3.9 MB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\teamd\\.conda\\envs\\torch\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\teamd\\.conda\\envs\\torch\\lib\\site-packages (from requests->torchvision) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\teamd\\.conda\\envs\\torch\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\teamd\\.conda\\envs\\torch\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\teamd\\.conda\\envs\\torch\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\teamd\\.conda\\envs\\torch\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.0.1\n",
      "    Uninstalling torch-2.0.1:\n",
      "      Successfully uninstalled torch-2.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\TeamD\\\\.conda\\\\envs\\\\torch\\\\Lib\\\\site-packages\\\\~-rch\\\\lib\\\\asmjit.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import speech_recognition as sr\n",
    "import requests\n",
    "import numpy as np\n",
    "import whisper\n",
    "from loguru import logger\n",
    "\n",
    "def continuous_transcription_whisper():\n",
    "    try:\n",
    "        r = sr.Recognizer()\n",
    "        audio_model = whisper.load_model(\"large-v2\", device=\"cuda\")\n",
    "        while True:  # Add an exit condition if needed\n",
    "            with sr.Microphone(sample_rate=16000) as source:\n",
    "                logger.info(\"Listening...\")\n",
    "                audio = r.listen(source)\n",
    "                np_audio = np.frombuffer(audio.get_raw_data(), np.int16).flatten().astype(np.float32) / 32768.0\n",
    "\n",
    "                try:\n",
    "                    result = audio_model.transcribe(np_audio, batch_size=16)\n",
    "                    text = str(result[\"text\"]).strip()  # Extract the transcribed text\n",
    "                    logger.info(f\"Transcribed: {text}\")\n",
    "                    \n",
    "                    # Sending the transcribed text to your FastAPI server\n",
    "                    requests.post(\"http://localhost:8000/say\", data=text)\n",
    "                    \n",
    "                except Exception as e:  # Modify this to catch specific exceptions you're expecting\n",
    "                    logger.error(f\"Error in transcription: {e}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in transcription background task: {e}\")\n",
    "\n",
    "transcription_thread = threading.Thread(target=continuous_transcription_whisper)\n",
    "transcription_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-22 01:15:57.453\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcontinuous_transcription_whisper\u001b[0m:\u001b[36m29\u001b[0m - \u001b[31m\u001b[1mError in transcription background task: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
