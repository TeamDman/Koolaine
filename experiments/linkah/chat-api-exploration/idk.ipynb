{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TeamD\\.conda\\envs\\sfm\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 880/880 [00:00<?, ?B/s] \n",
      "Downloading (…)former_sequential.py: 100%|██████████| 2.23k/2.23k [00:00<?, ?B/s]\n",
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/phi-1_5:\n",
      "- configuration_mixformer_sequential.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "Downloading (…)former_sequential.py: 100%|██████████| 32.2k/32.2k [00:00<00:00, 16.5MB/s]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "This modeling file requires the following packages that were not found in your environment: einops. Run `pip install einops`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\Repos\\Azure\\ca.teamdman.www\\teamdman.ca\\app\\src\\routes\\interesting\\linkah\\idk.ipynb Cell 1\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Repos/Azure/ca.teamdman.www/teamdman.ca/app/src/routes/interesting/linkah/idk.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Repos/Azure/ca.teamdman.www/teamdman.ca/app/src/routes/interesting/linkah/idk.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m torch\u001b[39m.\u001b[39mset_default_device(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Repos/Azure/ca.teamdman.www/teamdman.ca/app/src/routes/interesting/linkah/idk.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model \u001b[39m=\u001b[39m AutoModelForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39mmicrosoft/phi-1_5\u001b[39;49m\u001b[39m\"\u001b[39;49m, trust_remote_code\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, torch_dtype\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Repos/Azure/ca.teamdman.www/teamdman.ca/app/src/routes/interesting/linkah/idk.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mmicrosoft/phi-1_5\u001b[39m\u001b[39m\"\u001b[39m, trust_remote_code\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, torch_dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Repos/Azure/ca.teamdman.www/teamdman.ca/app/src/routes/interesting/linkah/idk.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m inputs \u001b[39m=\u001b[39m tokenizer(\u001b[39m'''\u001b[39m\u001b[39m```python\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Repos/Azure/ca.teamdman.www/teamdman.ca/app/src/routes/interesting/linkah/idk.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mdef print_prime(n):\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Repos/Azure/ca.teamdman.www/teamdman.ca/app/src/routes/interesting/linkah/idk.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m   \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Repos/Azure/ca.teamdman.www/teamdman.ca/app/src/routes/interesting/linkah/idk.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m   Print all primes between 1 and n\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Repos/Azure/ca.teamdman.www/teamdman.ca/app/src/routes/interesting/linkah/idk.ipynb#W0sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m   \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'''\u001b[39m, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m, return_attention_mask\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\TeamD\\.conda\\envs\\sfm\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:550\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[39mif\u001b[39;00m has_remote_code \u001b[39mand\u001b[39;00m trust_remote_code:\n\u001b[0;32m    549\u001b[0m     class_ref \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mauto_map[\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m]\n\u001b[1;32m--> 550\u001b[0m     model_class \u001b[39m=\u001b[39m get_class_from_dynamic_module(\n\u001b[0;32m    551\u001b[0m         class_ref, pretrained_model_name_or_path, code_revision\u001b[39m=\u001b[39mcode_revision, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhub_kwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    552\u001b[0m     )\n\u001b[0;32m    553\u001b[0m     _ \u001b[39m=\u001b[39m hub_kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mcode_revision\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    554\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(pretrained_model_name_or_path):\n",
      "File \u001b[1;32mc:\\Users\\TeamD\\.conda\\envs\\sfm\\lib\\site-packages\\transformers\\dynamic_module_utils.py:485\u001b[0m, in \u001b[0;36mget_class_from_dynamic_module\u001b[1;34m(class_reference, pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, repo_type, code_revision, **kwargs)\u001b[0m\n\u001b[0;32m    483\u001b[0m     code_revision \u001b[39m=\u001b[39m revision\n\u001b[0;32m    484\u001b[0m \u001b[39m# And lastly we get the class inside our newly created module\u001b[39;00m\n\u001b[1;32m--> 485\u001b[0m final_module \u001b[39m=\u001b[39m get_cached_module_file(\n\u001b[0;32m    486\u001b[0m     repo_id,\n\u001b[0;32m    487\u001b[0m     module_file \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m.py\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    488\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m    489\u001b[0m     force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[0;32m    490\u001b[0m     resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[0;32m    491\u001b[0m     proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m    492\u001b[0m     token\u001b[39m=\u001b[39;49mtoken,\n\u001b[0;32m    493\u001b[0m     revision\u001b[39m=\u001b[39;49mcode_revision,\n\u001b[0;32m    494\u001b[0m     local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[0;32m    495\u001b[0m     repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[0;32m    496\u001b[0m )\n\u001b[0;32m    497\u001b[0m \u001b[39mreturn\u001b[39;00m get_class_in_module(class_name, final_module\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m.py\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\TeamD\\.conda\\envs\\sfm\\lib\\site-packages\\transformers\\dynamic_module_utils.py:313\u001b[0m, in \u001b[0;36mget_cached_module_file\u001b[1;34m(pretrained_model_name_or_path, module_file, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, repo_type, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[39mraise\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[39m# Check we have all the requirements in our environment\u001b[39;00m\n\u001b[1;32m--> 313\u001b[0m modules_needed \u001b[39m=\u001b[39m check_imports(resolved_module_file)\n\u001b[0;32m    315\u001b[0m \u001b[39m# Now we move the module inside our cached dynamic modules.\u001b[39;00m\n\u001b[0;32m    316\u001b[0m full_submodule \u001b[39m=\u001b[39m TRANSFORMERS_DYNAMIC_MODULE_NAME \u001b[39m+\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39msep \u001b[39m+\u001b[39m submodule\n",
      "File \u001b[1;32mc:\\Users\\TeamD\\.conda\\envs\\sfm\\lib\\site-packages\\transformers\\dynamic_module_utils.py:179\u001b[0m, in \u001b[0;36mcheck_imports\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    176\u001b[0m         missing_packages\u001b[39m.\u001b[39mappend(imp)\n\u001b[0;32m    178\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing_packages) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 179\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m    180\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis modeling file requires the following packages that were not found in your environment: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    181\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(missing_packages)\u001b[39m}\u001b[39;00m\u001b[39m. Run `pip install \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(missing_packages)\u001b[39m}\u001b[39;00m\u001b[39m`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    182\u001b[0m     )\n\u001b[0;32m    184\u001b[0m \u001b[39mreturn\u001b[39;00m get_relative_imports(filename)\n",
      "\u001b[1;31mImportError\u001b[0m: This modeling file requires the following packages that were not found in your environment: einops. Run `pip install einops`"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "torch.set_default_device('cuda')\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-1_5\", trust_remote_code=True, torch_dtype=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-1_5\", trust_remote_code=True, torch_dtype=\"auto\")\n",
    "inputs = tokenizer('''```python\n",
    "def print_prime(n):\n",
    "   \"\"\"\n",
    "   Print all primes between 1 and n\n",
    "   \"\"\"''', return_tensors=\"pt\", return_attention_mask=False)\n",
    "\n",
    "outputs = model.generate(**inputs, max_length=200)\n",
    "text = tokenizer.batch_decode(outputs)[0]\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
